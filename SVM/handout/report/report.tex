\documentclass[a4paper, 11pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithm2e}
\usepackage[pdftex]{hyperref}
\usepackage{listings}
\input{listing_setting.tex}

% Lengths and indenting
\setlength{\textwidth}{16.5cm}
\setlength{\marginparwidth}{1.5cm}
\setlength{\parindent}{0cm}
\setlength{\parskip}{0.15cm}
\setlength{\textheight}{22cm}
\setlength{\oddsidemargin}{0cm}
\setlength{\evensidemargin}{\oddsidemargin}
\setlength{\topmargin}{0cm}
\setlength{\headheight}{0cm}
\setlength{\headsep}{0cm}

\renewcommand{\familydefault}{\sfdefault}

\title{Data Mining: Learning from Large Data Sets - Fall Semester 2015}
\author{fgmehlin@student.ethz.ch\\ matteopo@student.ethz.ch\\ piusv@student.ethz.ch\\}
\date{\today}

\begin{document}
\maketitle

\section*{Large Scale Image Classification} 
This project consists of training a model for classification of two images, namely : Nature and People. From a set of extracted feature, we applied made use of a Stochastic Gradient Descent classifier.
\section{Mapper}

The mapper is divided into two subsequent parts :
\begin{enumerate}
\item Feature transformation
\item Classification with Cross-validation
\end{enumerate}

1.) The method transforms applies the following transformation on the sample features :
\begin{itemize}
\item $\widetilde{x_1} = \sqrt{|x|}$
\item $\widetilde{x_2} = cosh((\frac{\pi}{2})*x) - 1$
\item $\widetilde{x_3} = sin((\frac{\pi}{2})*x)$
\end{itemize}

\textbf{NOTE}: We also tried to implement Random Fourier Feature transformation but they gave worse results that the aforementioned transformations.

2.) We use a Stochastic Gradient Descent Classifier algorithm with l1 regularizer provided by the sklearn library. In order to better estimate the classification error, we implemented a cross-validation module which works as following : \\

Every sample has probability p = 0.9 to get selected training, or p = 0.1 for validation. This simulates a 10-fold cross validation process where we try to compute the prediction error on the holdout data. By running multiple times this method, samples get selected randomly for validation and estimate the cross validation error.

Finally the mapper will output the tuple (1, feature\_weights) for the learned dataset.

\section{Reducer}

The reducer aggregates the weights from the different mappers to produce the final feature weights.

\section{Participation}



\end{document} 

